{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction This self-service course provides a general introduction to High Performance Computing (HPC) using EPCC's national HPC service ARCHER2 as the platform for the exercises. Details High-performance computing (HPC) is a fundamental technology used in solving scientific problems. Many of the grand challenges of science depend on simulations and models run on HPC facilities to make progress, for example: protein folding, the search for the Higgs boson, and developing nuclear fusion. This self-service course covers the the basic concepts underlying the drivers for HPC development, HPC hardware, software, programming models, applications, HPC usage, and application performance.This foundation will give the you ability to appreciate the relevance of HPC in your field and also equip you with the tools to start making effective use of HPC facilities yourself. Intended learning outcomes On completion of this course trainees should be able to explain: Why HPC? - What are the drivers and motivation? who uses it? HPC Hardware - Building blocks and architectures. Parallel computing - Programing models and implementations. Using HPC systems - Access, compilers, resource allocation and performance. Pre-requisites Trainees are expected to have experience using a desktop computer (Windows or Mac), but no programming, Linux, or HPC experience is necessary. Timetable This is a self-service course which you can work through at your own pace and in your own time. Each section contains an approximate guide to how long it would take to cover if it was delivered in traditional lecture style. Overview of EPCC Why HPC? HPC systems oview Exercise 1 - Connecting to and using a supercomputer Hardware and architecture details Parallel programming Exercise 2 - running parallel programs Parallel performance Exercise 3 - parallel performance","title":"Introduction"},{"location":"#introduction","text":"This self-service course provides a general introduction to High Performance Computing (HPC) using EPCC's national HPC service ARCHER2 as the platform for the exercises.","title":"Introduction"},{"location":"#details","text":"High-performance computing (HPC) is a fundamental technology used in solving scientific problems. Many of the grand challenges of science depend on simulations and models run on HPC facilities to make progress, for example: protein folding, the search for the Higgs boson, and developing nuclear fusion. This self-service course covers the the basic concepts underlying the drivers for HPC development, HPC hardware, software, programming models, applications, HPC usage, and application performance.This foundation will give the you ability to appreciate the relevance of HPC in your field and also equip you with the tools to start making effective use of HPC facilities yourself.","title":"Details"},{"location":"#intended-learning-outcomes","text":"On completion of this course trainees should be able to explain: Why HPC? - What are the drivers and motivation? who uses it? HPC Hardware - Building blocks and architectures. Parallel computing - Programing models and implementations. Using HPC systems - Access, compilers, resource allocation and performance.","title":"Intended learning outcomes"},{"location":"#pre-requisites","text":"Trainees are expected to have experience using a desktop computer (Windows or Mac), but no programming, Linux, or HPC experience is necessary.","title":"Pre-requisites"},{"location":"#timetable","text":"This is a self-service course which you can work through at your own pace and in your own time. Each section contains an approximate guide to how long it would take to cover if it was delivered in traditional lecture style. Overview of EPCC Why HPC? HPC systems oview Exercise 1 - Connecting to and using a supercomputer Hardware and architecture details Parallel programming Exercise 2 - running parallel programs Parallel performance Exercise 3 - parallel performance","title":"Timetable"},{"location":"EPCC/","text":"Overview of EPCC","title":"EPCC"},{"location":"EPCC/#overview-of-epcc","text":"","title":"Overview of EPCC"},{"location":"HPC_systems_overview/","text":"Basics of HPC systems What is a supercomputer? Linux, the command line, and SSH Some example systems Interactive vs Batch use Leads to: You should now try the first practical exercise: Exercise 1","title":"Basics of HPC systems"},{"location":"HPC_systems_overview/#basics-of-hpc-systems","text":"","title":"Basics of HPC systems"},{"location":"HPC_systems_overview/#what-is-a-supercomputer","text":"","title":"What is a supercomputer?"},{"location":"HPC_systems_overview/#linux-the-command-line-and-ssh","text":"","title":"Linux, the command line, and SSH"},{"location":"HPC_systems_overview/#some-example-systems","text":"","title":"Some example systems"},{"location":"HPC_systems_overview/#interactive-vs-batch-use","text":"","title":"Interactive vs Batch use"},{"location":"HPC_systems_overview/#leads-to","text":"You should now try the first practical exercise: Exercise 1","title":"Leads to:"},{"location":"hardware_and_architectures/","text":"HPC Hardware and architectures","title":"Hardware and architecture details"},{"location":"hardware_and_architectures/#hpc-hardware-and-architectures","text":"","title":"HPC Hardware and architectures"},{"location":"optimization/","text":"Optimization Basics of efficient programming (some basic C/C++ or Fortran knowldegde needed) Optimization caveats compiler flags Fast CPU operations vs microcode C vs Fortran style 2D array indexing Loop optimizations Avoiding branching Helping the compiler","title":"Optimization"},{"location":"optimization/#optimization","text":"Basics of efficient programming (some basic C/C++ or Fortran knowldegde needed) Optimization caveats compiler flags Fast CPU operations vs microcode C vs Fortran style 2D array indexing Loop optimizations Avoiding branching Helping the compiler","title":"Optimization"},{"location":"parallel_performance/","text":"Parallel performance Serial performance programming languages different compilers compiler flags strong scaling Amdahl's law Weak scaling Gustafson's law Other considerations Hybrid OpenMP and MPI","title":"Parallel performance"},{"location":"parallel_performance/#parallel-performance","text":"","title":"Parallel performance"},{"location":"parallel_performance/#serial-performance","text":"programming languages different compilers compiler flags","title":"Serial performance"},{"location":"parallel_performance/#strong-scaling","text":"Amdahl's law","title":"strong scaling"},{"location":"parallel_performance/#weak-scaling","text":"Gustafson's law","title":"Weak scaling"},{"location":"parallel_performance/#other-considerations","text":"Hybrid OpenMP and MPI","title":"Other considerations"},{"location":"parallel_programming/","text":"Parallel programming Parallel programing patterns Shared memory Distributed memory OpenMP MPI CUDA/GPU programming","title":"Parallel programming"},{"location":"parallel_programming/#parallel-programming","text":"","title":"Parallel programming"},{"location":"parallel_programming/#parallel-programing-patterns","text":"","title":"Parallel programing patterns"},{"location":"parallel_programming/#shared-memory","text":"","title":"Shared memory"},{"location":"parallel_programming/#distributed-memory","text":"","title":"Distributed memory"},{"location":"parallel_programming/#openmp","text":"","title":"OpenMP"},{"location":"parallel_programming/#mpi","text":"","title":"MPI"},{"location":"parallel_programming/#cudagpu-programming","text":"","title":"CUDA/GPU programming"},{"location":"why_HPC/","text":"What is HPC and why is it needed?","title":"Why HPC?"},{"location":"why_HPC/#what-is-hpc-and-why-is-it-needed","text":"","title":"What is HPC and why is it needed?"},{"location":"ex1/ex1/","text":"Practical exercise 1 In this practical exercise you will: Access ARCHER2, or Cirrus, or a Machine of your choice using SSH. Become familiar with linux and the command line. Compile and run serial code interactively. Submit serial and parallel programs to run using the batch system. The case study code for this exercise is a image sharpening program. The source code we will use is on this Github repo: https://github.com/sfarr-epcc/sharpen The exercise is split into a few parts that should be done in order: Theory of the case study program Part 1 - Connecting to a HPC machine with SSH Part 2 - Compilation and running Part 3 - Job submission","title":"Overview"},{"location":"ex1/ex1/#practical-exercise-1","text":"In this practical exercise you will: Access ARCHER2, or Cirrus, or a Machine of your choice using SSH. Become familiar with linux and the command line. Compile and run serial code interactively. Submit serial and parallel programs to run using the batch system. The case study code for this exercise is a image sharpening program. The source code we will use is on this Github repo: https://github.com/sfarr-epcc/sharpen The exercise is split into a few parts that should be done in order: Theory of the case study program Part 1 - Connecting to a HPC machine with SSH Part 2 - Compilation and running Part 3 - Job submission","title":"Practical exercise 1"},{"location":"ex1/part1/","text":"Part 1 This page covers how to log into a remote machine. SSH client To connect to a remote computer you will need a SSH client. SSH is a tool that allows us to connect to and use a remote computer as our own. Please follow the directions below to install an SSH client for your system if you do not already have one. Windows Modern versions of Windows have SSH available in Powershell. You can test if it is available by typing ssh --help in Powershell. If it is installed, you should see some useful output. If it is not installed, you will get an error. If SSH is not available in Powershell, then you should install MobaXterm from http://mobaxterm.mobatek.net . You will want to get the Home edition (Installer edition). However, if Powershell works, you do not need this. macOS macOS comes with SSH pre-installed, so you should not need to install anything. Use your \"Terminal\" app. Linux Linux users do not need to install anything, you should be set! Use your terminal application. Connecting to ARCHER2 Sign up for an account on ARCHER2 through SAFE Login to SAFE Go to the Menu \"Login accounts\" and select \"Request login account\" Choose the TODO project \u201cChoose Project for Machine Account\u201d box and click \"Next\" On the next page, the ARCHER2 system should be selected. Click \"Next\" Enter the username you would prefer to use on ARCHER2. Every username must be unique, so if your chosen name is taken, you will need to choose another Now you have to wait for the course organiser to accept your request to register. When this has happened, your account will be created on ARCHER2. Once this has been done, you should be sent an email. If you have not received an email but believe that your account should have been activated, check your account status in SAFE which will also show when the account has been activated. You can then pick up your one shot initial password for ARCHER2 from your SAFE account. Generate an SSH key pair and upload it to SAFE In addition to your password, you will need an SSH key pair to access ARCHER2. There is useful guidance on how to generate SSH key pairs in the ARCHER2 documentation . Once you have generated your key pair, you need to add the public part to your ARCHER2 account in SAFE: Login to SAFE Go to the Menu \u201cLogin accounts\u201d and select the ARCHER2 account you want to add the SSH key to On the subsequent Login account details page click the \u201cAdd Credential\u201d button Select \u201cSSH public key\u201d as the Credential Type and click \u201cNext\u201d Either copy and paste the public part of your SSH key into the \u201cSSH Public key\u201d box or use the button to select the public key file on your computer. Click \u201cAdd\u201d to associate the public SSH key part with your account The public SSH key part will now be added to your login account on the ARCHER2 system. Log into ARCHER2 You should now be able to log into ARCHER2 by following the login instructions in the ARCHER2 documentation . E.g: ssh username@login.archer2.ac.uk Note If you are using ARCHER2 before you download the files you should move to the /work filesystem: cd /work/[project code]/[group code]/[username] The /work filesystem is a high performance parallel file system that can be accessed by both the frontend login nodes and the compute nodes. All jobs on ARCHER2 should be run from the /work file system. ARCHER2 compute nodes cannot access the /home file system at all. Any jobs attempting to use /home will fail with an error. For more information the ARCHER2 documentation: https://docs.archer2.ac.uk/user-guide/io/#using-the-archer2-file-systems","title":"Part 1"},{"location":"ex1/part1/#part-1","text":"This page covers how to log into a remote machine.","title":"Part 1"},{"location":"ex1/part1/#ssh-client","text":"To connect to a remote computer you will need a SSH client. SSH is a tool that allows us to connect to and use a remote computer as our own. Please follow the directions below to install an SSH client for your system if you do not already have one. Windows Modern versions of Windows have SSH available in Powershell. You can test if it is available by typing ssh --help in Powershell. If it is installed, you should see some useful output. If it is not installed, you will get an error. If SSH is not available in Powershell, then you should install MobaXterm from http://mobaxterm.mobatek.net . You will want to get the Home edition (Installer edition). However, if Powershell works, you do not need this. macOS macOS comes with SSH pre-installed, so you should not need to install anything. Use your \"Terminal\" app. Linux Linux users do not need to install anything, you should be set! Use your terminal application.","title":"SSH client"},{"location":"ex1/part1/#connecting-to-archer2","text":"","title":"Connecting to ARCHER2"},{"location":"ex1/part1/#sign-up-for-an-account-on-archer2-through-safe","text":"Login to SAFE Go to the Menu \"Login accounts\" and select \"Request login account\" Choose the TODO project \u201cChoose Project for Machine Account\u201d box and click \"Next\" On the next page, the ARCHER2 system should be selected. Click \"Next\" Enter the username you would prefer to use on ARCHER2. Every username must be unique, so if your chosen name is taken, you will need to choose another Now you have to wait for the course organiser to accept your request to register. When this has happened, your account will be created on ARCHER2. Once this has been done, you should be sent an email. If you have not received an email but believe that your account should have been activated, check your account status in SAFE which will also show when the account has been activated. You can then pick up your one shot initial password for ARCHER2 from your SAFE account.","title":"Sign up for an account on ARCHER2 through SAFE"},{"location":"ex1/part1/#generate-an-ssh-key-pair-and-upload-it-to-safe","text":"In addition to your password, you will need an SSH key pair to access ARCHER2. There is useful guidance on how to generate SSH key pairs in the ARCHER2 documentation . Once you have generated your key pair, you need to add the public part to your ARCHER2 account in SAFE: Login to SAFE Go to the Menu \u201cLogin accounts\u201d and select the ARCHER2 account you want to add the SSH key to On the subsequent Login account details page click the \u201cAdd Credential\u201d button Select \u201cSSH public key\u201d as the Credential Type and click \u201cNext\u201d Either copy and paste the public part of your SSH key into the \u201cSSH Public key\u201d box or use the button to select the public key file on your computer. Click \u201cAdd\u201d to associate the public SSH key part with your account The public SSH key part will now be added to your login account on the ARCHER2 system.","title":"Generate an SSH key pair and upload it to SAFE"},{"location":"ex1/part1/#log-into-archer2","text":"You should now be able to log into ARCHER2 by following the login instructions in the ARCHER2 documentation . E.g: ssh username@login.archer2.ac.uk Note If you are using ARCHER2 before you download the files you should move to the /work filesystem: cd /work/[project code]/[group code]/[username] The /work filesystem is a high performance parallel file system that can be accessed by both the frontend login nodes and the compute nodes. All jobs on ARCHER2 should be run from the /work file system. ARCHER2 compute nodes cannot access the /home file system at all. Any jobs attempting to use /home will fail with an error. For more information the ARCHER2 documentation: https://docs.archer2.ac.uk/user-guide/io/#using-the-archer2-file-systems","title":"Log into ARCHER2"},{"location":"ex1/part2/","text":"Part 2 This page covers how to download, compile, and run code. Downloading the source code In this exercise we will be using a image sharpening program. The source code is available in a Github repository. To download the code you will need to clone the repository. To do this execute the following command git clone https://github.com/sfarr-epcc/sharpen.git The output will look similar to this Cloning into 'sharpen'... remote: Enumerating objects: 21, done. remote: Counting objects: 100% (21/21), done. remote: Compressing objects: 100% (15/15), done. remote: Total 21 (delta 7), reused 16 (delta 5), pack-reused 0 Receiving objects: 100% (21/21), 314.18 KiB | 2.51 MiB/s, done. Resolving deltas: 100% (7/7), done. You will now have a folder called sharpen . Change directory into it and list the contents cd sharpen ls Output C-OMP C-SER README.md There are two version of the code, a serial version and a parallel version. Initially we will be looking at the serial version located in the C-SER folder. Compiling the source code We will compile the serial version of the source code using a Makefile. Move into the C-SER directory and list the contents. cd C-SER ls Output: cio.c dosharpen.c filter.c fuzzy.pgm Makefile sharpen.c sharpen.h utilities.c utilities.h You will see that there are various code files. The Makefile contains the commands to compile them together to produce the executable program. To use the Makefile type make command. make Output: cc -g -DC_SERIAL_PRACTICAL -c sharpen.c cc -g -DC_SERIAL_PRACTICAL -c dosharpen.c cc -g -DC_SERIAL_PRACTICAL -c filter.c cc -g -DC_SERIAL_PRACTICAL -c cio.c cc -g -DC_SERIAL_PRACTICAL -c utilities.c cc -g -DC_SERIAL_PRACTICAL -o sharpen sharpen.o dosharpen.o filter.o cio.o utilities.o -lm This should produce an executable file called sharpen . Running the serial program We can run the serial program directly on the login nodes ./sharpen Output: Image sharpening code running in serial Input file is: fuzzy.pgm Image size is 564 x 770 Using a filter of size 17 x 17 Reading image file: fuzzy.pgm ... done Starting calculation ... Program on core 0-255 ... finished Writing output file: sharpened.pgm ... done Calculation time was 3.697039 seconds Overall run time was 3.923524 seconds Viewing the images To view the images on the remote machine you will need to make sure you an X window client installed on your local machine and you have logged into the remote machine with X forwarding enabled. To view images on ARCHER2 you can use: module load xview xview file.pgm Note Here we have introduced the module command, this is a way of controlling the software environment typically used on HPC machines. A module is a self-contained description of a software package -- it contains the settings required to run a software package and, usually, encodes required dependencies on other software packages. Alternatively you can download the files to your local machine via SSH ( scp , rysnc , or stfp ) and open them with an image viewing program e.g. preview on MacOS. The images should look like this: In the next step we will run the parallel version of the code on the compute nodes using the SLURM job submission system.","title":"Part 2"},{"location":"ex1/part2/#part-2","text":"This page covers how to download, compile, and run code.","title":"Part 2"},{"location":"ex1/part2/#downloading-the-source-code","text":"In this exercise we will be using a image sharpening program. The source code is available in a Github repository. To download the code you will need to clone the repository. To do this execute the following command git clone https://github.com/sfarr-epcc/sharpen.git The output will look similar to this Cloning into 'sharpen'... remote: Enumerating objects: 21, done. remote: Counting objects: 100% (21/21), done. remote: Compressing objects: 100% (15/15), done. remote: Total 21 (delta 7), reused 16 (delta 5), pack-reused 0 Receiving objects: 100% (21/21), 314.18 KiB | 2.51 MiB/s, done. Resolving deltas: 100% (7/7), done. You will now have a folder called sharpen . Change directory into it and list the contents cd sharpen ls Output C-OMP C-SER README.md There are two version of the code, a serial version and a parallel version. Initially we will be looking at the serial version located in the C-SER folder.","title":"Downloading the source code"},{"location":"ex1/part2/#compiling-the-source-code","text":"We will compile the serial version of the source code using a Makefile. Move into the C-SER directory and list the contents. cd C-SER ls Output: cio.c dosharpen.c filter.c fuzzy.pgm Makefile sharpen.c sharpen.h utilities.c utilities.h You will see that there are various code files. The Makefile contains the commands to compile them together to produce the executable program. To use the Makefile type make command. make Output: cc -g -DC_SERIAL_PRACTICAL -c sharpen.c cc -g -DC_SERIAL_PRACTICAL -c dosharpen.c cc -g -DC_SERIAL_PRACTICAL -c filter.c cc -g -DC_SERIAL_PRACTICAL -c cio.c cc -g -DC_SERIAL_PRACTICAL -c utilities.c cc -g -DC_SERIAL_PRACTICAL -o sharpen sharpen.o dosharpen.o filter.o cio.o utilities.o -lm This should produce an executable file called sharpen .","title":"Compiling the source code"},{"location":"ex1/part2/#running-the-serial-program","text":"We can run the serial program directly on the login nodes ./sharpen Output: Image sharpening code running in serial Input file is: fuzzy.pgm Image size is 564 x 770 Using a filter of size 17 x 17 Reading image file: fuzzy.pgm ... done Starting calculation ... Program on core 0-255 ... finished Writing output file: sharpened.pgm ... done Calculation time was 3.697039 seconds Overall run time was 3.923524 seconds","title":"Running the serial program"},{"location":"ex1/part2/#viewing-the-images","text":"To view the images on the remote machine you will need to make sure you an X window client installed on your local machine and you have logged into the remote machine with X forwarding enabled. To view images on ARCHER2 you can use: module load xview xview file.pgm Note Here we have introduced the module command, this is a way of controlling the software environment typically used on HPC machines. A module is a self-contained description of a software package -- it contains the settings required to run a software package and, usually, encodes required dependencies on other software packages. Alternatively you can download the files to your local machine via SSH ( scp , rysnc , or stfp ) and open them with an image viewing program e.g. preview on MacOS. The images should look like this: In the next step we will run the parallel version of the code on the compute nodes using the SLURM job submission system.","title":"Viewing the images"},{"location":"ex1/part3/","text":"Part 3 This page covers running parallel code on compute nodes using the job submission system. Compile the parallel version of the code cd C-OMP make Output: cc -fopenmp -g -DC_OPENMP_PRACTICAL -c sharpen.c cc -fopenmp -g -DC_OPENMP_PRACTICAL -c dosharpen.c cc -fopenmp -g -DC_OPENMP_PRACTICAL -c filter.c cc -fopenmp -g -DC_OPENMP_PRACTICAL -c cio.c cc -fopenmp -g -DC_OPENMP_PRACTICAL -c utilities.c cc -fopenmp -g -DC_OPENMP_PRACTICAL -o sharpen sharpen.o dosharpen.o filter.o cio.o utilities.o -lm To run this code in parallel it should be submitted to the compute nodes using Slurm workload manager. Running on the compute nodes The use of compute nodes on ARCHER2 is mediated by the Slurm job submission system. Slurm is a scheduler which is used to ensure that all users get access to their fair share of resources, to make sure that the machine is as efficiently used as possible and to allow user to run jobs without having to be physically logged in. Whilst it is possible to run interactive jobs (jobs where you log directly into the compute nodes and run your executable there), and they are useful for debugging and development, they are not ideal for running long and/or large numbers of production jobs as you need to be physically interacting with the system to use them. The solution to this, and the method that users generally use to run jobs on systems like ARCHER2, is to run in batch mode. In this case you put the commands you wish to run in a file (called a job script) and the system executes the commands in sequence for you with no need for you to be interacting. Using Slurm job scripts You will notice in the C-OMP folder there is a Slurm script archer2.slurm . If you open it using a text editor ( nano , vi , or emacs ). nano archer2.slurm archer2.slurm #!/bin/bash #SBATCH --job-name=sharpen #SBATCH --nodes=1 #SBATCH --tasks-per-node=1 #SBATCH --cpus-per-task=4 #SBATCH --time=00:01:00 # Replace [budget code] below with your project code (e.g. t01) #SBATCH --account=[budget code] #SBATCH --partition=standard #SBATCH --qos=standard # Setup the batch environment module load epcc-job-env # Set the number of threads to the CPUs per task export OMP_NUM_THREADS = $SLURM_CPUS_PER_TASK # Launch the parallel job srun --hint = nomultithread --distribution = block:block ./sharpen This is an OpenMP program so we control the number of parallel threads used with the --cpus-per-task variable. To submit the job to run on the compute nodes we use the sbatch command sbatch archer2.slurm Output: Submitted batch job 1793266 Where the number is the unique job ID. Note On ARCHER2 you must submit jobs from the /work filesystem. Monitoring the batch job The slurm command squeue can be used to show the status of the jobs. Without any options or arguments it lists all jobs known by the scheduler. squeue To show just your jobs add the -u $USER option squeue -u $USER Note that for this example it runs very quickly so you may not see it in the queue before it finishes running. Finding the output The Slurm system places the output from your job in a file called slurm-<jobID>.out . You can view it using the cat command cat slurm-1793266.out Output: Image sharpening code running on 4 thread(s) Input file is: fuzzy.pgm Image size is 564 x 770 Using a filter of size 17 x 17 Reading image file: fuzzy.pgm ... done Starting calculation ... Thread 0 on core 0 Thread 1 on core 1 Thread 2 on core 2 Thread 3 on core 3 ... finished Writing output file: sharpened.pgm ... done Calculation time was 0.970780 seconds Overall run time was 1.124198 seconds Investigating the parallel speedup You should now investigate how the calculation time and overall run time change as the number of threads is increased. To do this just edit the #SBATCH --cpus-per-task=4 variable to a different number and resubmit the job. Because this is an OpenMP program it will not scale beyond one node which is 128 cores on ARCHER2. You will notice that two timings are reported: the calculation time, and the overall runtime. The first excludes the file input/output operations. The speedup is calculated by diving the the time taken to run on one core by the time taken to run using N cores. For this program you can calculate the speedup for both the calculation time and the overall runtime The results for ARCHER2 are shown below Investigating the parallel speedup You will notice that two timings are reported: the calculation time, and the overall runtime. The first excludes the file input/output operations. The speedup is calculated by diving the the time taken to run on one core by the time taken to run using N cores. For this program you can calculate the speedup for both the calculation time and the overall runtime Example speedup results for ARCHER2 are shown below.","title":"Part 3"},{"location":"ex1/part3/#part-3","text":"This page covers running parallel code on compute nodes using the job submission system.","title":"Part 3"},{"location":"ex1/part3/#compile-the-parallel-version-of-the-code","text":"cd C-OMP make Output: cc -fopenmp -g -DC_OPENMP_PRACTICAL -c sharpen.c cc -fopenmp -g -DC_OPENMP_PRACTICAL -c dosharpen.c cc -fopenmp -g -DC_OPENMP_PRACTICAL -c filter.c cc -fopenmp -g -DC_OPENMP_PRACTICAL -c cio.c cc -fopenmp -g -DC_OPENMP_PRACTICAL -c utilities.c cc -fopenmp -g -DC_OPENMP_PRACTICAL -o sharpen sharpen.o dosharpen.o filter.o cio.o utilities.o -lm To run this code in parallel it should be submitted to the compute nodes using Slurm workload manager.","title":"Compile the parallel version of the code"},{"location":"ex1/part3/#running-on-the-compute-nodes","text":"The use of compute nodes on ARCHER2 is mediated by the Slurm job submission system. Slurm is a scheduler which is used to ensure that all users get access to their fair share of resources, to make sure that the machine is as efficiently used as possible and to allow user to run jobs without having to be physically logged in. Whilst it is possible to run interactive jobs (jobs where you log directly into the compute nodes and run your executable there), and they are useful for debugging and development, they are not ideal for running long and/or large numbers of production jobs as you need to be physically interacting with the system to use them. The solution to this, and the method that users generally use to run jobs on systems like ARCHER2, is to run in batch mode. In this case you put the commands you wish to run in a file (called a job script) and the system executes the commands in sequence for you with no need for you to be interacting.","title":"Running on the compute nodes"},{"location":"ex1/part3/#using-slurm-job-scripts","text":"You will notice in the C-OMP folder there is a Slurm script archer2.slurm . If you open it using a text editor ( nano , vi , or emacs ). nano archer2.slurm archer2.slurm #!/bin/bash #SBATCH --job-name=sharpen #SBATCH --nodes=1 #SBATCH --tasks-per-node=1 #SBATCH --cpus-per-task=4 #SBATCH --time=00:01:00 # Replace [budget code] below with your project code (e.g. t01) #SBATCH --account=[budget code] #SBATCH --partition=standard #SBATCH --qos=standard # Setup the batch environment module load epcc-job-env # Set the number of threads to the CPUs per task export OMP_NUM_THREADS = $SLURM_CPUS_PER_TASK # Launch the parallel job srun --hint = nomultithread --distribution = block:block ./sharpen This is an OpenMP program so we control the number of parallel threads used with the --cpus-per-task variable. To submit the job to run on the compute nodes we use the sbatch command sbatch archer2.slurm Output: Submitted batch job 1793266 Where the number is the unique job ID. Note On ARCHER2 you must submit jobs from the /work filesystem.","title":"Using Slurm job scripts"},{"location":"ex1/part3/#monitoring-the-batch-job","text":"The slurm command squeue can be used to show the status of the jobs. Without any options or arguments it lists all jobs known by the scheduler. squeue To show just your jobs add the -u $USER option squeue -u $USER Note that for this example it runs very quickly so you may not see it in the queue before it finishes running.","title":"Monitoring the batch job"},{"location":"ex1/part3/#finding-the-output","text":"The Slurm system places the output from your job in a file called slurm-<jobID>.out . You can view it using the cat command cat slurm-1793266.out Output: Image sharpening code running on 4 thread(s) Input file is: fuzzy.pgm Image size is 564 x 770 Using a filter of size 17 x 17 Reading image file: fuzzy.pgm ... done Starting calculation ... Thread 0 on core 0 Thread 1 on core 1 Thread 2 on core 2 Thread 3 on core 3 ... finished Writing output file: sharpened.pgm ... done Calculation time was 0.970780 seconds Overall run time was 1.124198 seconds","title":"Finding the output"},{"location":"ex1/part3/#investigating-the-parallel-speedup","text":"You should now investigate how the calculation time and overall run time change as the number of threads is increased. To do this just edit the #SBATCH --cpus-per-task=4 variable to a different number and resubmit the job. Because this is an OpenMP program it will not scale beyond one node which is 128 cores on ARCHER2. You will notice that two timings are reported: the calculation time, and the overall runtime. The first excludes the file input/output operations. The speedup is calculated by diving the the time taken to run on one core by the time taken to run using N cores. For this program you can calculate the speedup for both the calculation time and the overall runtime The results for ARCHER2 are shown below","title":"Investigating the parallel speedup"},{"location":"ex1/part3/#investigating-the-parallel-speedup_1","text":"You will notice that two timings are reported: the calculation time, and the overall runtime. The first excludes the file input/output operations. The speedup is calculated by diving the the time taken to run on one core by the time taken to run using N cores. For this program you can calculate the speedup for both the calculation time and the overall runtime Example speedup results for ARCHER2 are shown below.","title":"Investigating the parallel speedup"},{"location":"ex1/theory/","text":"Image sharpening program Images can be fuzzy from random noise and blurrings. A image can be sharpened by: detecting the edges combining the edges with the original image These steps are shown in figure 1. Figure 1. Image sharpening steps. Edge detection Edges can be detected using a Laplacian filter. The Laplacian \\(L(x,y)\\) is the second spatial derivative of the image intensity \\(I(x,y)\\) , this means it highlights regions of rapid intensity change, i.e the edges. \\( L(x,y) = \\frac{\\partial^2 I }{\\partial x^2} + \\frac{\\partial^2 I }{\\partial y^2} \\) In practice this detects noise in the image as edges, therefore a smoothing filter is applied first which takes the form of a Guassian. The Guassian filter \\(G(x,y)\\) approximates each pixel as a weighted average of its neighbors. \\( G(x,y) = \\frac{1}{2 \\pi \\sigma^2} e^{- (x^2+y^2)/(2 \\sigma^2)} \\) The two operations can be combined to give the Laplacian of Gaussian filter \\(LoG(x,y)\\) . \\( LoG(x,y) = -\\frac{1}{\\pi \\sigma^4} \\left( 1 - \\frac{x^2+y^2}{2 \\sigma^2}\\right) e^{- (x^2+y^2)/(2 \\sigma^2)} \\) These two fuctions \\(G(x,y)\\) and \\(LoG(x,y)\\) are graphed in figure 2. Figure 2. Gaussian and Laplacian of Gaussian filters Implementation To apply the LoG filter to an image the LoG filter must be turned into a discrete mask, that is a matrix of size 2d+1 x 2d+1 where d is an integer. We use d=8, therefore the LoG filter is a 17x17 square, it looks like this: Figure 3. LoG filter as a discerete mask To perform the convolution of this filter with original image the following operation is performed on each pixel \\( edges(i,j) = \\sum_{k=-d}^d \\sum_{k=-d}^d image(i + k, j + l) \\times filter(k,l) \\) The sharpened image is then created by adding the edges to the original image, with a scaling factor (See the source code for the full details).","title":"Theory"},{"location":"ex1/theory/#image-sharpening-program","text":"Images can be fuzzy from random noise and blurrings. A image can be sharpened by: detecting the edges combining the edges with the original image These steps are shown in figure 1. Figure 1. Image sharpening steps.","title":"Image sharpening program"},{"location":"ex1/theory/#edge-detection","text":"Edges can be detected using a Laplacian filter. The Laplacian \\(L(x,y)\\) is the second spatial derivative of the image intensity \\(I(x,y)\\) , this means it highlights regions of rapid intensity change, i.e the edges. \\( L(x,y) = \\frac{\\partial^2 I }{\\partial x^2} + \\frac{\\partial^2 I }{\\partial y^2} \\) In practice this detects noise in the image as edges, therefore a smoothing filter is applied first which takes the form of a Guassian. The Guassian filter \\(G(x,y)\\) approximates each pixel as a weighted average of its neighbors. \\( G(x,y) = \\frac{1}{2 \\pi \\sigma^2} e^{- (x^2+y^2)/(2 \\sigma^2)} \\) The two operations can be combined to give the Laplacian of Gaussian filter \\(LoG(x,y)\\) . \\( LoG(x,y) = -\\frac{1}{\\pi \\sigma^4} \\left( 1 - \\frac{x^2+y^2}{2 \\sigma^2}\\right) e^{- (x^2+y^2)/(2 \\sigma^2)} \\) These two fuctions \\(G(x,y)\\) and \\(LoG(x,y)\\) are graphed in figure 2. Figure 2. Gaussian and Laplacian of Gaussian filters","title":"Edge detection"},{"location":"ex1/theory/#implementation","text":"To apply the LoG filter to an image the LoG filter must be turned into a discrete mask, that is a matrix of size 2d+1 x 2d+1 where d is an integer. We use d=8, therefore the LoG filter is a 17x17 square, it looks like this: Figure 3. LoG filter as a discerete mask To perform the convolution of this filter with original image the following operation is performed on each pixel \\( edges(i,j) = \\sum_{k=-d}^d \\sum_{k=-d}^d image(i + k, j + l) \\times filter(k,l) \\) The sharpened image is then created by adding the edges to the original image, with a scaling factor (See the source code for the full details).","title":"Implementation"},{"location":"ex2/ex2/","text":"Practical exercise 2 In this practical exercise you will: Compile and run MPI code. Investigate parallel taskfarms and worksharing. The case study code for this exercise is a program which calculates the Mandelbrot and Julia sets. The source code can be found on this Github repository: https://github.com/sfarr-epcc/fractal The exercise is split into a few parts which should be done in order: - Theory of the case study program - Part 1 - Part 2","title":"Overview"},{"location":"ex2/ex2/#practical-exercise-2","text":"In this practical exercise you will: Compile and run MPI code. Investigate parallel taskfarms and worksharing. The case study code for this exercise is a program which calculates the Mandelbrot and Julia sets. The source code can be found on this Github repository: https://github.com/sfarr-epcc/fractal The exercise is split into a few parts which should be done in order: - Theory of the case study program - Part 1 - Part 2","title":"Practical exercise 2"},{"location":"ex2/part1/","text":"Part 1 This page covers how to download, compile, and run the example code. Downloading the code To download the code you will need to clone the repository. To do this execute the following command: git clone https://github.com/sfarr-epcc/fractal.git Compiling the code Enter the directory and compile the code using the Makefile. cd fractal make The compiled program will be called fractal Initial run The fractal program is designed to be run in parallel using MPI. If you try and run it in serial it will print an error message: ./fractal ERROR: need at least two processes for the task farm! To run using MPI you will need to submit a job to the compute nodes. The output will look similar to the output below: --------- CONFIGURATION OF THE TASKFARM RUN --------- Number of processes: 17 Image size: 768 x 768 Task size: 192 x 192 (pixels) Number of iterations: 5000 Coordinates in X dimension: -2.000000 to 1.000000 Coordinates in Y dimension: -1.500000 to 1.500000 Fractal function is: Mandelbrot set -----Workload Summary (number of iterations)--------- Total Number of Workers: 16 Total Number of Tasks: 16 Total Worker Load: 498023053 Average Worker Load: 31126440 Maximum Worker Load: 156694685 Minimum Worker Load: 62822 Time taken by 16 workers was 1.212222 (secs) Load Imbalance Factor: 5.034134 The fractal executable will take a number of parameters and produce a fractal image in a file called output.ppm . By default the image will be overlaid with blocks in different shades, which correspond to the work done by different processors. This way we can see how the tasks were allocated. An example of this is presented in figure 1 \u2013 the image is divided into 16 tasks (squares) and different shade corresponds to each of 16 workers. Example output image created using 16 workers and 16 tasks. The default run scripts do the following: srun -n 17 ./fractal -t 192 This creates a task farm with one master process and 16 workers. The master divides the image up into tasks, where each task is a square of the size of 192 by 192 pixels. The default image size is 768 x 768 pixels, which means there is exactly one task per worker, i.e. we are not yet doing anything to balance the load. Note that we control the number of tasks through the task size. ( #SBATCH --tasks-per-node=<N> , or srun -n <N> , or mpirun -np <N> ). The load of a worker is estimated as the total number of iterations of the Mandelbrot calculation summed over all the pixels considered by that worker. The assumption is that the time taken is proportional to this. The only time that is actually measured is the total time taken to complete the calculation. You can view the output file using display output.ppm , an example of which is found in figure 1. If you want to see how the image looks without the shading use the \u2013n option to the fractal program - see the following parameter section for more details. Fractal program Parameters The following options are recognised by the fractal program: -S number of pixels in the x-axis of image -I maximum number of iterations -x the x-minimum coordinate -y the y-minimum coordinate -f <fractal function> set to J for Julia set -c the real part of the parameter c+iC for the Julia set -C the imaginary part of the parameter c+iC for the julia set -t task size (pixels x pixels) -n do not shade output image based on task allocation to workers","title":"Part 1"},{"location":"ex2/part1/#part-1","text":"This page covers how to download, compile, and run the example code.","title":"Part 1"},{"location":"ex2/part1/#downloading-the-code","text":"To download the code you will need to clone the repository. To do this execute the following command: git clone https://github.com/sfarr-epcc/fractal.git","title":"Downloading the code"},{"location":"ex2/part1/#compiling-the-code","text":"Enter the directory and compile the code using the Makefile. cd fractal make The compiled program will be called fractal","title":"Compiling the code"},{"location":"ex2/part1/#initial-run","text":"The fractal program is designed to be run in parallel using MPI. If you try and run it in serial it will print an error message: ./fractal ERROR: need at least two processes for the task farm! To run using MPI you will need to submit a job to the compute nodes. The output will look similar to the output below: --------- CONFIGURATION OF THE TASKFARM RUN --------- Number of processes: 17 Image size: 768 x 768 Task size: 192 x 192 (pixels) Number of iterations: 5000 Coordinates in X dimension: -2.000000 to 1.000000 Coordinates in Y dimension: -1.500000 to 1.500000 Fractal function is: Mandelbrot set -----Workload Summary (number of iterations)--------- Total Number of Workers: 16 Total Number of Tasks: 16 Total Worker Load: 498023053 Average Worker Load: 31126440 Maximum Worker Load: 156694685 Minimum Worker Load: 62822 Time taken by 16 workers was 1.212222 (secs) Load Imbalance Factor: 5.034134 The fractal executable will take a number of parameters and produce a fractal image in a file called output.ppm . By default the image will be overlaid with blocks in different shades, which correspond to the work done by different processors. This way we can see how the tasks were allocated. An example of this is presented in figure 1 \u2013 the image is divided into 16 tasks (squares) and different shade corresponds to each of 16 workers. Example output image created using 16 workers and 16 tasks. The default run scripts do the following: srun -n 17 ./fractal -t 192 This creates a task farm with one master process and 16 workers. The master divides the image up into tasks, where each task is a square of the size of 192 by 192 pixels. The default image size is 768 x 768 pixels, which means there is exactly one task per worker, i.e. we are not yet doing anything to balance the load. Note that we control the number of tasks through the task size. ( #SBATCH --tasks-per-node=<N> , or srun -n <N> , or mpirun -np <N> ). The load of a worker is estimated as the total number of iterations of the Mandelbrot calculation summed over all the pixels considered by that worker. The assumption is that the time taken is proportional to this. The only time that is actually measured is the total time taken to complete the calculation. You can view the output file using display output.ppm , an example of which is found in figure 1. If you want to see how the image looks without the shading use the \u2013n option to the fractal program - see the following parameter section for more details.","title":"Initial run"},{"location":"ex2/part1/#fractal-program-parameters","text":"The following options are recognised by the fractal program: -S number of pixels in the x-axis of image -I maximum number of iterations -x the x-minimum coordinate -y the y-minimum coordinate -f <fractal function> set to J for Julia set -c the real part of the parameter c+iC for the Julia set -C the imaginary part of the parameter c+iC for the julia set -t task size (pixels x pixels) -n do not shade output image based on task allocation to workers","title":"Fractal program Parameters"},{"location":"ex2/part2/","text":"Part 2 Run tests To explore the effect of the load balancing run the code with different number of workers and tasks and try to answer the following questions: From the default run with 16 workers and 16 tasks, what is your predicted best runtime based on the load imbalance factor? Look at the output for 16 tasks \u2013 can you understand how the load was distributed across workers by looking at the colours of the bands and the structure of the Mandelbrot set? Increase the number of tasks by decreasing the task size; does the runtime approach what you predicted? Look at the colour bands: how does the task distribution change? Are the results qualitatively different if you use more workers? For 16 workers, run the program with ever smaller task sizes (i.e. more tasks) and plot a graph of runtime against number of tasks. You should ensure you measure all the way up to the maximum number of tasks, i.e. a task size of a single pixel. Can you explain the form of the graph? Does the minimum runtime approach what you predicted from the load imbalance factor? You can experiment with varying the parameters, e.g. plotting the same graph with more workers or using the Julia set rather than the Mandelbrot set. The number of workers is controlled by the \u2013n argument to srun and is one fewer than P (the total number of processes) as we always require one dedicated process to be the controller.","title":"Part 2"},{"location":"ex2/part2/#part-2","text":"","title":"Part 2"},{"location":"ex2/part2/#run-tests","text":"To explore the effect of the load balancing run the code with different number of workers and tasks and try to answer the following questions: From the default run with 16 workers and 16 tasks, what is your predicted best runtime based on the load imbalance factor? Look at the output for 16 tasks \u2013 can you understand how the load was distributed across workers by looking at the colours of the bands and the structure of the Mandelbrot set? Increase the number of tasks by decreasing the task size; does the runtime approach what you predicted? Look at the colour bands: how does the task distribution change? Are the results qualitatively different if you use more workers? For 16 workers, run the program with ever smaller task sizes (i.e. more tasks) and plot a graph of runtime against number of tasks. You should ensure you measure all the way up to the maximum number of tasks, i.e. a task size of a single pixel. Can you explain the form of the graph? Does the minimum runtime approach what you predicted from the load imbalance factor? You can experiment with varying the parameters, e.g. plotting the same graph with more workers or using the Julia set rather than the Mandelbrot set. The number of workers is controlled by the \u2013n argument to srun and is one fewer than P (the total number of processes) as we always require one dedicated process to be the controller.","title":"Run tests"},{"location":"ex2/theory/","text":"Fractal calculation program Mandelbrot Set The Mandelbrot set is a famous example of a fractal in mathematics. It is a set of complex numbers \\(c\\) for which the function \\(f_c(z) = z^2 + c\\) does not diverge to infinity when iterated from \\(z=0\\) , i.e the values of \\(c\\) for which the sequence \\([ c,\\ c^2+c,\\ (c^2+c)^2+c,\\ ((c^2+c)^2+c)^2+c,\\ ...]\\) remains bounded. The complex numbers can be thought of as 2d coordinates, that is a complex number \\(z\\) with real part \\(a\\) and imaginary part \\(b\\) ( \\(z = a + ib\\) ) can be written as \\((a, b)\\) . The coordinates can be plotted as an image, where the color corresponds to the number of iterations required before the escape condition is reached. The escape condition is when we have confirmed that the sequence is not bounded, this is when the magnitude of \\(z\\) , the current value in the iteration, is greater than 2. The pseudo code for this is for each x , y coordinate x0 , y0 = x , y x = 0 y = 0 iteration = 0 while ( iteration < max_iterations and x ^ 2 + y ^ 2 <= 4 ) x_next = x ^ 2 + y ^ 2 + x0 y_next = 2 * x * y + y0 iteration = iteration + 1 x = x_next y = y_next return color_map ( iteration ) Note that for points within the Mandelbrot set the condition will never be met, hence the need to set the upper bound max_iterations . The Julia set is another example of a complex number set. From the parallel programming point of view the useful feature of the Mandelbrot and Julia sets is that the calculation for each point is independent i.e. whether one point lies within the set or not is not affected by other points. Parallel Programming Concepts Task farm Task farming is one of the common approaches used to parallelise applications. Its main idea is to automatically create pools of calculations (called tasks), dispatch them to the processes and the to collect the results. The process responsible for creating this pool of jobs is known as a source , sometimes it is also called a master or controller process . The process collecting the results is called a sink . Quite often one process plays both roles \u2013 it creates, distributes tasks and collects results. It is also possible to have a team of source and sink process. A \u2018farm\u2019 of one or more workers claims jobs from the source, executes them and returns results to the sink. The workers continually claim jobs (usually complete one task then ask for another) until the pool is exhausted. Figure 1 shows the basic concept of how a task farm is structured. *Figure 1. Schematic representation of a simeple task farm. In summary processes can assume the following roles: - Source - creates and distributes tasks - Worker processes - complete tasks received from the source process and then send results to the sink process - Sink - gathers results from worker processes. Having learned what a task farm is, consider the following questions: - What types of problems could be parallelised using the task farm approach? What types of problems would not benefit from it? Why? - What kind of computer architecture could fully utilise the task farm benefits? Using a task farm As you may have guessed a task farm is commonly used in large computations composed of many independent calculations. Only when calculations are independent is it possible to assign tasks in the most effective way, and thus speed up the overall calculation with the most efficiency. After all, if the tasks are independent from each other, the processors can request them as they become available, i.e. usually after they complete their current task, without worrying about the order in which tasks are completed. This dynamic allocation of tasks is an effective method for getting more use out of the compute resources. It is inevitable that some calculations will take longer to complete than others, so using methods such as a lock-step calculation (waiting on the whole set of processors to finish a current job) or pre-distributing all tasks at the beginning would lead to wasted compute cycles. Of course, not all problems can be parallelised using a task farm approach. Not always a task farm While many problems can be broken down into individual parts, there are a sizeable number of problems where this approach will not work. Problems which involve lots of inter-process communication are often not suitable for task farms as they require the master to track which worker has which element, and to tell workers which other workers have which elements to allow them to communicate. Additionally, the sink progress may need to track this as well in cases of output order dependency. It is possible to use task farms to parallelise problems that require a lot of communications, however, in such cases drawbacks and overheads impacting the performance would be incurred. As mentioned before, to determine the points lying within the Mandelbrot set there is no need for the communications between the worker tasks, which makes it an embarrassingly parallel problem that is suitable for task-farming. Although the calculation can employ the task farm approach, we still need to consider how to use it in the most optimal way. Consider the following scenarios: - How do you think the performance would be affected if you were to use more, equal and fewer tasks than workers? - In your opinion what would be the optimal combination of the number of workers and task? What would it depend on the most? Task size? Problem size? Computer architecture? Load Balancing The factor deciding the effectiveness of a task farm is a task distribution. A way in which a master process determines how the tasks are distributed across the workers it called a load balancing. A successful load balancing will avoid overloading a single worker, maximising the throughput of the system and making best use of resources available. Poor load balancing will cause some workers of the system to be idle and consequently other elements to be \u2018overworked\u2019, leading to increased computation time and significantly reduced performance. Poor load balancing Figure 2 shows how careless task distribution can affect the completion time. Clearly, CPU2 needs more time to complete its tasks, particularly compared to CPU3. The total runtime is equivalent to the longest runtime on any of the CPUs so the calculation time will be longer than it would be if the resource were used optimally. This can occur when load balancing is not considered, random scheduling is used (although this is not always bad) or poor decisions are made about the job sizes. Figure 2. Poor load balance Good Load Balancing Figure 3 shows how by scheduling jobs carefully, the best use of the resources can be made. By choosing a distribution strategy to optimise the use of resources, the CPUs in the diagram all complete their tasks at roughly the same time. This means that no one task has been overloaded with work and dominated the running time of the overall calculation. This can be achieved by many different means. For example, if the task sizes and running times are known in advance, the jobs can be scheduled to allow best resource usage. The most common distribution is to distribute large jobs first and then distribute progressively smaller jobs to equal out the workload. If the job sizes can change or the running times are unknown, then an adaptive system could be used which tries to infer future task lengths based upon observed runtimes. Figure 3. Good load balance. The fractal program you will be using employs a queue strategy \u2013 tasks are queued waiting for workers, which completed their previous task, to claim them from the top of the queue. This ensures that workers that happen to get shorter tasks will complete more tasks, so that they finish roughly at the same time as workers with longer tasks. Quantifying the load imbalance We can try to quantify how well balanced a task farm is by computing the load imbalance factor, which we define as: \\( \\text{load imbalance factor} = \\frac{\\text{Workload of most loaded worker}}{\\text{average workload of workers}} \\) For a perfect load-balanced calculation this will be equal to 1.0, which is equivalent to all workers having exactly the same amount of work. In general, it will be greater than 1.0. It is a useful measure because it allows you to predict what the runtime would be for a perfectly balanced load on the same number of workers, assuming that no additional overheads are introduced due to load balancing. For example, if the load imbalance factor is 2.0 then this implies that, in principle, we could halve the runtime (reduce it by a factor of 2) if the load were perfectly balanced.","title":"Theory"},{"location":"ex2/theory/#fractal-calculation-program","text":"","title":"Fractal calculation program"},{"location":"ex2/theory/#mandelbrot-set","text":"The Mandelbrot set is a famous example of a fractal in mathematics. It is a set of complex numbers \\(c\\) for which the function \\(f_c(z) = z^2 + c\\) does not diverge to infinity when iterated from \\(z=0\\) , i.e the values of \\(c\\) for which the sequence \\([ c,\\ c^2+c,\\ (c^2+c)^2+c,\\ ((c^2+c)^2+c)^2+c,\\ ...]\\) remains bounded. The complex numbers can be thought of as 2d coordinates, that is a complex number \\(z\\) with real part \\(a\\) and imaginary part \\(b\\) ( \\(z = a + ib\\) ) can be written as \\((a, b)\\) . The coordinates can be plotted as an image, where the color corresponds to the number of iterations required before the escape condition is reached. The escape condition is when we have confirmed that the sequence is not bounded, this is when the magnitude of \\(z\\) , the current value in the iteration, is greater than 2. The pseudo code for this is for each x , y coordinate x0 , y0 = x , y x = 0 y = 0 iteration = 0 while ( iteration < max_iterations and x ^ 2 + y ^ 2 <= 4 ) x_next = x ^ 2 + y ^ 2 + x0 y_next = 2 * x * y + y0 iteration = iteration + 1 x = x_next y = y_next return color_map ( iteration ) Note that for points within the Mandelbrot set the condition will never be met, hence the need to set the upper bound max_iterations . The Julia set is another example of a complex number set. From the parallel programming point of view the useful feature of the Mandelbrot and Julia sets is that the calculation for each point is independent i.e. whether one point lies within the set or not is not affected by other points.","title":"Mandelbrot Set"},{"location":"ex2/theory/#parallel-programming-concepts","text":"","title":"Parallel Programming Concepts"},{"location":"ex2/theory/#task-farm","text":"Task farming is one of the common approaches used to parallelise applications. Its main idea is to automatically create pools of calculations (called tasks), dispatch them to the processes and the to collect the results. The process responsible for creating this pool of jobs is known as a source , sometimes it is also called a master or controller process . The process collecting the results is called a sink . Quite often one process plays both roles \u2013 it creates, distributes tasks and collects results. It is also possible to have a team of source and sink process. A \u2018farm\u2019 of one or more workers claims jobs from the source, executes them and returns results to the sink. The workers continually claim jobs (usually complete one task then ask for another) until the pool is exhausted. Figure 1 shows the basic concept of how a task farm is structured. *Figure 1. Schematic representation of a simeple task farm. In summary processes can assume the following roles: - Source - creates and distributes tasks - Worker processes - complete tasks received from the source process and then send results to the sink process - Sink - gathers results from worker processes. Having learned what a task farm is, consider the following questions: - What types of problems could be parallelised using the task farm approach? What types of problems would not benefit from it? Why? - What kind of computer architecture could fully utilise the task farm benefits?","title":"Task farm"},{"location":"ex2/theory/#using-a-task-farm","text":"As you may have guessed a task farm is commonly used in large computations composed of many independent calculations. Only when calculations are independent is it possible to assign tasks in the most effective way, and thus speed up the overall calculation with the most efficiency. After all, if the tasks are independent from each other, the processors can request them as they become available, i.e. usually after they complete their current task, without worrying about the order in which tasks are completed. This dynamic allocation of tasks is an effective method for getting more use out of the compute resources. It is inevitable that some calculations will take longer to complete than others, so using methods such as a lock-step calculation (waiting on the whole set of processors to finish a current job) or pre-distributing all tasks at the beginning would lead to wasted compute cycles. Of course, not all problems can be parallelised using a task farm approach.","title":"Using a task farm"},{"location":"ex2/theory/#not-always-a-task-farm","text":"While many problems can be broken down into individual parts, there are a sizeable number of problems where this approach will not work. Problems which involve lots of inter-process communication are often not suitable for task farms as they require the master to track which worker has which element, and to tell workers which other workers have which elements to allow them to communicate. Additionally, the sink progress may need to track this as well in cases of output order dependency. It is possible to use task farms to parallelise problems that require a lot of communications, however, in such cases drawbacks and overheads impacting the performance would be incurred. As mentioned before, to determine the points lying within the Mandelbrot set there is no need for the communications between the worker tasks, which makes it an embarrassingly parallel problem that is suitable for task-farming. Although the calculation can employ the task farm approach, we still need to consider how to use it in the most optimal way. Consider the following scenarios: - How do you think the performance would be affected if you were to use more, equal and fewer tasks than workers? - In your opinion what would be the optimal combination of the number of workers and task? What would it depend on the most? Task size? Problem size? Computer architecture?","title":"Not always a task farm"},{"location":"ex2/theory/#load-balancing","text":"The factor deciding the effectiveness of a task farm is a task distribution. A way in which a master process determines how the tasks are distributed across the workers it called a load balancing. A successful load balancing will avoid overloading a single worker, maximising the throughput of the system and making best use of resources available. Poor load balancing will cause some workers of the system to be idle and consequently other elements to be \u2018overworked\u2019, leading to increased computation time and significantly reduced performance.","title":"Load Balancing"},{"location":"ex2/theory/#poor-load-balancing","text":"Figure 2 shows how careless task distribution can affect the completion time. Clearly, CPU2 needs more time to complete its tasks, particularly compared to CPU3. The total runtime is equivalent to the longest runtime on any of the CPUs so the calculation time will be longer than it would be if the resource were used optimally. This can occur when load balancing is not considered, random scheduling is used (although this is not always bad) or poor decisions are made about the job sizes. Figure 2. Poor load balance","title":"Poor load balancing"},{"location":"ex2/theory/#good-load-balancing","text":"Figure 3 shows how by scheduling jobs carefully, the best use of the resources can be made. By choosing a distribution strategy to optimise the use of resources, the CPUs in the diagram all complete their tasks at roughly the same time. This means that no one task has been overloaded with work and dominated the running time of the overall calculation. This can be achieved by many different means. For example, if the task sizes and running times are known in advance, the jobs can be scheduled to allow best resource usage. The most common distribution is to distribute large jobs first and then distribute progressively smaller jobs to equal out the workload. If the job sizes can change or the running times are unknown, then an adaptive system could be used which tries to infer future task lengths based upon observed runtimes. Figure 3. Good load balance. The fractal program you will be using employs a queue strategy \u2013 tasks are queued waiting for workers, which completed their previous task, to claim them from the top of the queue. This ensures that workers that happen to get shorter tasks will complete more tasks, so that they finish roughly at the same time as workers with longer tasks.","title":"Good Load Balancing"},{"location":"ex2/theory/#quantifying-the-load-imbalance","text":"We can try to quantify how well balanced a task farm is by computing the load imbalance factor, which we define as: \\( \\text{load imbalance factor} = \\frac{\\text{Workload of most loaded worker}}{\\text{average workload of workers}} \\) For a perfect load-balanced calculation this will be equal to 1.0, which is equivalent to all workers having exactly the same amount of work. In general, it will be greater than 1.0. It is a useful measure because it allows you to predict what the runtime would be for a perfectly balanced load on the same number of workers, assuming that no additional overheads are introduced due to load balancing. For example, if the load imbalance factor is 2.0 then this implies that, in principle, we could halve the runtime (reduce it by a factor of 2) if the load were perfectly balanced.","title":"Quantifying the load imbalance"},{"location":"ex3/ex3/","text":"Practical exercise 3 In this exercise you will: Be introduced to domain decomposition parallel programming methods. Perform benchmarking of a case-study code, investigating the strong scaling, the weak scaling, and hybrid MPI/OpenMPI parallelisation. The case study code for this exercise is GROMACS a molecular dynamics package. The exercise is split into a few part which should be done in order Theory Part 1 - Strong scaling Part 2 - Weak scaling Part 3 - Hybrid OpenMP/MPI","title":"Overview"},{"location":"ex3/ex3/#practical-exercise-3","text":"In this exercise you will: Be introduced to domain decomposition parallel programming methods. Perform benchmarking of a case-study code, investigating the strong scaling, the weak scaling, and hybrid MPI/OpenMPI parallelisation. The case study code for this exercise is GROMACS a molecular dynamics package. The exercise is split into a few part which should be done in order Theory Part 1 - Strong scaling Part 2 - Weak scaling Part 3 - Hybrid OpenMP/MPI","title":"Practical exercise 3"},{"location":"ex3/part1/","text":"Part 1 In this section you will run a benchmark simulation and investigate the strong scaling parallel performance. The benchmark system The system we will used from the HECBIOSIM bechmark suite: https://www.hecbiosim.ac.uk/access-hpc/benchmarks We will focus on the 465K atom system: 465K atom system - hEGFR Dimer of 1IVO and 1NQL - Total number of atoms = 465,399 - Protein atoms = 21,749 Lipid atoms = 134,268 Water atoms = 309,087 Ions = 295 The input file can be obtained from https://www.hecbiosim.ac.uk/access-hpc/benchmarks, or from our git repo: TODO Running the benchmark An example slurm script to run the benchmark on ARCHER2 is shown below gmx_archer2.slurm #!/bin/bash #SBATCH --job-name=gmx_bench #SBATCH --nodes=1 #SBATCH --tasks-per-node=128 #SBATCH --cpus-per-task=1 #SBATCH --time=00:10:00 # Replace [budget code] below with your project code (e.g. t01) #SBATCH --account=z19 #SBATCH --partition=standard #SBATCH --qos=standard # Setup the environment module load gromacs export OMP_NUM_THREADS = 1 srun --distribution = block:block --hint = nomultithread gmx_mpi mdrun -s bench_465kHBS.tpr -v The bottom of the md.log file will contain the performance timings, e.g: Core t ( s ) Wall t ( s ) ( % ) Time: 12283 .520 95 .966 12799 .9 ( ns/day ) ( hour/ns ) Performance: 18 .008 1 .333 The most useful numbers to us are the wall-time 95.966s , and the performance: 18.008 ns/day which tells us how much simulation time (in nano-seconds) can be simulated for 1 day of wall-clock time. Things to investigate You should vary the number of nodes of plot the performance. This investigates the strong scaling of the program. What node count would you use for a long production simulation? Previous benchmarks for this system can be found here: https://www.hecbiosim.ac.uk/access-hpc/our-benchmark-results/archer2-benchmarks We have plotted our results for version 2021.3 of gromacs on ARCHER2 here:","title":"Part 1"},{"location":"ex3/part1/#part-1","text":"In this section you will run a benchmark simulation and investigate the strong scaling parallel performance.","title":"Part 1"},{"location":"ex3/part1/#the-benchmark-system","text":"The system we will used from the HECBIOSIM bechmark suite: https://www.hecbiosim.ac.uk/access-hpc/benchmarks We will focus on the 465K atom system: 465K atom system - hEGFR Dimer of 1IVO and 1NQL - Total number of atoms = 465,399 - Protein atoms = 21,749 Lipid atoms = 134,268 Water atoms = 309,087 Ions = 295 The input file can be obtained from https://www.hecbiosim.ac.uk/access-hpc/benchmarks, or from our git repo: TODO","title":"The benchmark system"},{"location":"ex3/part1/#running-the-benchmark","text":"An example slurm script to run the benchmark on ARCHER2 is shown below gmx_archer2.slurm #!/bin/bash #SBATCH --job-name=gmx_bench #SBATCH --nodes=1 #SBATCH --tasks-per-node=128 #SBATCH --cpus-per-task=1 #SBATCH --time=00:10:00 # Replace [budget code] below with your project code (e.g. t01) #SBATCH --account=z19 #SBATCH --partition=standard #SBATCH --qos=standard # Setup the environment module load gromacs export OMP_NUM_THREADS = 1 srun --distribution = block:block --hint = nomultithread gmx_mpi mdrun -s bench_465kHBS.tpr -v The bottom of the md.log file will contain the performance timings, e.g: Core t ( s ) Wall t ( s ) ( % ) Time: 12283 .520 95 .966 12799 .9 ( ns/day ) ( hour/ns ) Performance: 18 .008 1 .333 The most useful numbers to us are the wall-time 95.966s , and the performance: 18.008 ns/day which tells us how much simulation time (in nano-seconds) can be simulated for 1 day of wall-clock time.","title":"Running the benchmark"},{"location":"ex3/part1/#things-to-investigate","text":"You should vary the number of nodes of plot the performance. This investigates the strong scaling of the program. What node count would you use for a long production simulation? Previous benchmarks for this system can be found here: https://www.hecbiosim.ac.uk/access-hpc/our-benchmark-results/archer2-benchmarks We have plotted our results for version 2021.3 of gromacs on ARCHER2 here:","title":"Things to investigate"},{"location":"ex3/part2/","text":"Part 2 In this section you will use a different benchmark system and investigate the weak scaling parallel performance. The benchmark system The benchmark system we will use to investigate the weak scaling is a box of water. This is a simple system than can be created for different system sizes. The initial box size is 5nm x 5nm x 5nm and contains 884 water molecules. We have provided input files for this system water_x1.tpr and multiple larger systems with 2, 4, 8, ... up to 8096 times the volume ( water_x2.tpr , water_x4.tpr , water_x8.tpr , ... , water_8096.tpr ). Running the benchmark The benchmarks are designed such that water_x1.tpr is a suitable size for running on 1 core. (GROMACS works best with ~1000 atoms per CPU) An example slurm script to run the benchmark on ARCHER2 is shown below gmx_archer2.slurm #!/bin/bash #SBATCH --job-name=gmx_bench #SBATCH --nodes=1 #SBATCH --tasks-per-node=1 #SBATCH --cpus-per-task=1 #SBATCH --time=00:10:00 # Replace [budget code] below with your project code (e.g. t01) #SBATCH --account=z19 #SBATCH --partition=standard #SBATCH --qos=standard # Setup the environment module load gromacs export OMP_NUM_THREADS = 1 srun --distribution = block:block --hint = nomultithread gmx_mpi mdrun -s water_x1.tpr -v Make sure that nodes` x tasks-per-node = the system size. i.e for water_x256.tpr use --nodes=2 and --tasks-per-node=128`` Once again the important number is the ns/day figure. Things to investigate You should run the benchmarks systems where the number of cores used scales with the system size. I.e run water_x1.tpr with 1 core, water_x2.tpr with 2 cores, water_128.tpr with 128 cores etc. This investigates the weak scaling Plot the results and look at the difference between the intra-node and inter-node scaling. We have plotted our results for version 2021.3 of GROMACS on ARCHER2 below:","title":"Part 2"},{"location":"ex3/part2/#part-2","text":"In this section you will use a different benchmark system and investigate the weak scaling parallel performance.","title":"Part 2"},{"location":"ex3/part2/#the-benchmark-system","text":"The benchmark system we will use to investigate the weak scaling is a box of water. This is a simple system than can be created for different system sizes. The initial box size is 5nm x 5nm x 5nm and contains 884 water molecules. We have provided input files for this system water_x1.tpr and multiple larger systems with 2, 4, 8, ... up to 8096 times the volume ( water_x2.tpr , water_x4.tpr , water_x8.tpr , ... , water_8096.tpr ).","title":"The benchmark system"},{"location":"ex3/part2/#running-the-benchmark","text":"The benchmarks are designed such that water_x1.tpr is a suitable size for running on 1 core. (GROMACS works best with ~1000 atoms per CPU) An example slurm script to run the benchmark on ARCHER2 is shown below gmx_archer2.slurm #!/bin/bash #SBATCH --job-name=gmx_bench #SBATCH --nodes=1 #SBATCH --tasks-per-node=1 #SBATCH --cpus-per-task=1 #SBATCH --time=00:10:00 # Replace [budget code] below with your project code (e.g. t01) #SBATCH --account=z19 #SBATCH --partition=standard #SBATCH --qos=standard # Setup the environment module load gromacs export OMP_NUM_THREADS = 1 srun --distribution = block:block --hint = nomultithread gmx_mpi mdrun -s water_x1.tpr -v Make sure that nodes` x tasks-per-node = the system size. i.e for water_x256.tpr use --nodes=2 and --tasks-per-node=128`` Once again the important number is the ns/day figure.","title":"Running the benchmark"},{"location":"ex3/part2/#things-to-investigate","text":"You should run the benchmarks systems where the number of cores used scales with the system size. I.e run water_x1.tpr with 1 core, water_x2.tpr with 2 cores, water_128.tpr with 128 cores etc. This investigates the weak scaling Plot the results and look at the difference between the intra-node and inter-node scaling. We have plotted our results for version 2021.3 of GROMACS on ARCHER2 below:","title":"Things to investigate"},{"location":"ex3/part3/","text":"Part3 In this section we will look at the performance of hybrid OpenMP and MPI execution, we will be using the benchmark system from part 1.","title":"Part 3"},{"location":"ex3/part3/#part3","text":"In this section we will look at the performance of hybrid OpenMP and MPI execution, we will be using the benchmark system from part 1.","title":"Part3"},{"location":"ex3/theory/","text":"Molecular Simulation Molecular Dynamics is a method to perform Molecular Simulation research. Aim: Generate enough representative confirmations of the molecular system in such a way that accurate values of a property can be obtained. Example: Protein ion channel in a lipid bi-layer Typical questions: - How fast do ions pass through channels? - What happens when protein residues are altered? - How and where do ligands bind to the channel? - How is the lipid bi-layer composed locally? One Method: Molecular Dynamics Molecular Dynamics Uses Newton's equations of motion to generate configurations (a trajectory) for atoms of a molecular system. \\( m\\frac{d^2x}{dt^2} = F \\) \\( F = - \\nabla U \\) These are integrated using a Verlet-Like integrator, the Velocity-Verlet formulation is GROMACS GROMACS is a command line MD package that can perform most aspects of a MD workflow","title":"Theory"},{"location":"ex3/theory/#molecular-simulation","text":"Molecular Dynamics is a method to perform Molecular Simulation research. Aim: Generate enough representative confirmations of the molecular system in such a way that accurate values of a property can be obtained. Example: Protein ion channel in a lipid bi-layer Typical questions: - How fast do ions pass through channels? - What happens when protein residues are altered? - How and where do ligands bind to the channel? - How is the lipid bi-layer composed locally? One Method: Molecular Dynamics","title":"Molecular Simulation"},{"location":"ex3/theory/#molecular-dynamics","text":"Uses Newton's equations of motion to generate configurations (a trajectory) for atoms of a molecular system. \\( m\\frac{d^2x}{dt^2} = F \\) \\( F = - \\nabla U \\) These are integrated using a Verlet-Like integrator, the Velocity-Verlet formulation is","title":"Molecular Dynamics"},{"location":"ex3/theory/#gromacs","text":"GROMACS is a command line MD package that can perform most aspects of a MD workflow","title":"GROMACS"}]}